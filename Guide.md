# Building:
## Prerequisites:
This projects uses the boost C++ libraries, ispc for vectorizing the code and
cmake for the build system. Please make sure that the ispc binary is in path
for cmake to automatically detect it.

## Configure
Create an out-of-source build directory and run ccmake to configure the build:

ccmake <miniapps_src_dir>

To configure for cross compiling for Xeon Phi (MIC) run the following instead:

ccmake \
  -DCMAKE_TOOLCHAIN_FILE=<miniapps_src_dir>/cmake/stampede-mic-toolchain.cmake \
  <mini_apps_src_dir>

This tool-chain file is known to work on stampede.tacc.utexas.edu. It might
require some modifications on other systems.

ccmake allows you to interactively set build configurations variables.
Following are some the the important variables to consider:

* CMAKE_BUILD_TYPE: Make sure to set it to Release for performance testing.
* MARCHING_CUBES_ISPC_GANG_SIZE, POISSON_SOLVER_ISPC_GANG_SIZE, TET_MESH_CONT_ISPC_GANG_SIZE: The gang size to be used for each of the mini apps.
* MARCHING_CUBES_ISPC_ISA, POISSON_SOLVER_ISPC_ISA, TET_MESH_CONT_ISPC_ISA: The ISA to be targeted by ispc. This option is not available on MICs.
* MARCHING_CUBES_TYPE_DOUBLE, POISSON_SOLVER_TYPE_DOUBLE, TET_MESH_CONT_TYPE_DOUBLE: If this is ON, the datasets will be processed in double format, else they will be processed in float format.

Please note that not all combinations of ISA and gang-size is supported by
ispc. Please refer to ispc for supported configurations.

## Build:
After choosing an appropriate configuration, generate the makefiles and run
make to build the apps.
The built binaries can be found in the bin folder under the build directory.

# The Applications:

Running the applications without any parameters will display their usage.
Following is an overview of each of the mini apps.

## Marching Cubes:
This method computes isosurfaces from 3D volumetric data. It's input is a
3D array of scalar values and a value (iso-value) for which the iso-surface
will be generated. The isosurface is represented as a 3D triangle mesh.

The input data is represented by a single flattened array of scalars with
meta data about the volume's dimensions, origin and spacing.

The output polygonal data is represented by an array of 3D points stored in aos
format (x0, y0, z0, x1, y1, z1, ... , xn-1, yn-1, zn-1), an array of point
normals stored in the same format, and an array of indexes into the
point/normal arrays where each set of three indexes are the indexes of the
vertices of a triangle.

The method processes the input one cell at a time (a cell is a cube formed
by 8 neighboring samples). Hence the name Marching Cubes. All these cells can
be processed independently of each other, potentially in parallel.
A cell may contain zero to five triangles of the isosurface, based on the
values of its eight points.
The triangles are generated by a simple look up into a table of triangles
configurations.
Each cell configuration can be represented by an 8-bit integer value, a bit
is 1 if the corresponding cell-point is greater than or equal to the iso-value,
and 0 otherwise.
Hence the look-up table has 256 entries.
Each entry of the look up table gives a list of ids (0-11)
which represent the edges of the cube where the vertices of the triangles lie.
The order of the list also encodes the orientation of the triangles.
The exact position of a vertex is computed by interpolating the position of the
edge end-points based on the scalar values at those points.
Vertex normals can also be computed in a similar manner by interpolating the
gradients at the end points.
Since neighboring cubes share edges, duplicate vertices may be generated due to
the independent processing.
It is typically worthwhile to identify and remove the duplicates to reduce
the generated polygon's size.
This part may become a point of contention if the cubes are being processed in
parallel.

We have two main versions of this method, each with two implementations - a
scalar implementation using regular C++ and a vectorized implementation
using ispc.

The first version is a straight-forward implementation of the above
description.
We perform an iteration over each cell. For each cell the index into
the triangles configurations look-up table is computed.
If the cell has triangles, the gradients and position for the 8 points are
computed. Then for each edge where a vertex lies, the position and gradients
are interpolated.
For identifying duplicates, a Point Locator data structure is used which
divides the data range into bins to reduce the number of comparisons.
The vectorized version functions slightly differently.
An initial pass is performed to find the look-up index of each cell.
Based on the indexes, the arrays for points, normals and indexes are
preallocated. A second pass is performed to generate the triangles.
Finally the points array is checked to remove duplicates using the
Point Locator data structure. This step is not vectorized.
Another simple vectorized implementation tests if, instead of vectorizing the
whole algorithm, only vectorizing some short-vector based parts
(gradient computation and linear interpolation in this case), would give some
reasonable performance improvements.

The second version was implemented from scratch specifically to be easy to
vectorize. The algorithm is divided in to stages, where some intermediate
stages just reformat the data from previous stage, to be easy to process in the
next vector stage.
In the first stage the cells are iterated over and a list of their lookup
indexes is generated. This step can be reasonably vectorized.
In the second stage indexes that wont result in any triangles are removed and
the list is sorted. This stage cannot be easily vectorized but sorting the
list improves coherence for the next stage.
In the third stage each lookup index is examined and an array of edges is
generated, where each edge has a vertex lying on it. The edges are identified
by a unique edge id. Each point in the dataset is assigned (at most) three
edges---the edges that have it as one end point with the other end point
along the positive x, y, and z axises respectively. Points on the boundary
will have fewer than three edges but none will have more than three.
The unique edge-id is computed as: (point_index * 3 + [x=0,y=1,z=2]).
This stage can also be reasonably vectorized.
The edge list is then sorted and the duplicates removed in the fourth stage.
This takes care of removing duplicate vertices without the need for a point
locator data structure. The required index array for the output is also
generated at this stage.
In the final stage, for each edge, the position and the gradients of its
endpoints are computed and they are interpolated to compute the vertex
corresponding to the edge. This stage can also be easily vectorized.
We timed each of the stages to determine which of the vectorizable
stages were most expensive and would benefit from vectorization. We found that
most of the time was spent in the first stage. The other stages were taking
insignificant time and were not worth vectorizing. Therefore the vector
implementation of this version only vectorizes the first stage of this version.

We implemented another, slightly modified, second version. The idea was that
since the later stages were not worth vectorizing, they should be combined into
a single, efficient scalar implementation. We combine stages three and four
into a single scalar stage, which avoids some overhead of sorting and other
reformatting. This is the fastest version we have for this application.


## Unstructured Grid Contouring (Marching Tetrahedra)
This method computes an isosurface from a 3D unstructured tetrahedra mesh.
The input is an unstructured tetrahedra mesh represented by an array of points,
an array of point scalars, and an array of indexes, where each set of 4 indexes
are the indexes into the point and scalar array for the 4 vertexes of a
tetrahedron. The output isosurface is represented as a triangle polygon as
described in the Marching Cubes section.

Similar to marching cubes, each tetrahedra of the input mesh can be
processed independently and in parallel.
For each tetrahedra there may be from 0 to 2 triangles within it.
This is also computed with the help of a lookup table. A 4 bit index is
generated based on the scalar values at the four points of the tetrahedron.
This index is used to lookup into a 16 entry table of triangle configurations,
same as the table in marching cubes.
For each edge of a tetrahedron that is identified as having a vertex lying on
it, the position of its endpoints is computed and the vertex position is
interpolated from them. This method can also generate duplicate vertices
which can be removed using the Point Locator data structure as described above.
We have also implemented a faster way of identifying duplicates by
using hash tables. The indexes of the end points of an edge is used as the
edge's hash key. Therefore edges shared between tetrahedra will be identified
as duplicates.
The vertex normals are initialized to zero. When a new triangle is
generated, its surface normal is computed and added to the normals
of each vertex of the triangle. Finally the normals are normalized.

We have implemented one scalar and two vectorized versions of this method.
The scalar version is a straight forward implementation of the above
description.

Because of the unstructured nature of the input data, there are a lot of
indirections and gather/scatter involved with this method.
The first vectorized version pre-processes the input data to lay it out in
a AOSOA format with the hope that the overhead would be worth it.
First, the lookup index for each tetrahedron is computed. Empty tetrahedra
are discarded and the remaining are sorted by their lookup index.
A data structure is generated which stores the following information about
these tetrahedra in AOSOA format:
* Its original index
* Its lookup index
* the indexes of the four vertices
* the scalar values at the four vertices
* the position of the four vertices

This array is processed by a vectorized function that computes the triangles
of the isosurface. A scalar code then goes through the list of triangles and
merges duplicate vertices and also generates the index array. Finally, a
vectorized function normalizes all the vertex normals.

The second vectorized version is a direct port of the scalar version code
to ispc, followed by vectorization of different portions as much as possible,
without changing the actual flow. The rationale behind this version was
to see how much better or worse a direct port would perform. Ideally the
performance should increase, even if slightly, or at least stay the same,
since nothing extra is being done compared to the scalar version.
But realistically, there is still some overhead of just vectorization through
ispc.

# Initial Results
We have run some tests to profile the performance of each implementation.
Following are the machine the tests were run on:
* Core i7 4900MQ @ 2.8 GHz
* Xeon Phi SE10P (KNC)

Following are the datasets* the tests were run on:
* Volume datasets:
  * PlasticSkull: 256x256x160 scalars
  * VisibleHuman: 512x512x512 scalars
* Tetrahedra Mesh datasets:
  * PlasticSkull: Num Points = 10,485,760  Num Tets = 51,694,875
  * VisibleHuman: Num Points = 16,842,752  Num Tets = 83,232,000

Tests were run using both float and double scalar values. On the Core i7 CPU,
tests were run with avx2 ISA and gang sizes 8 and 16. On Xeon Phi, a gang size
of 16 only was tested. Following are the results (all times are in seconds):

## Marching Cubes
### CPU: Core i7, Precision: float, Gang size: 8
```
|            |scalar|   shortvec   |    simd      |scalar 2|    simd2     |scalar 2.1|   simd 2.1   |
|            |      | time |speedup| time |speedup|        | time |speedup|          | time |speedup|
|------------|------|------|-------|------|-------|--------|------|-------|----------|------|-------|
|PlasticSkull|0.335 |0.376 |0.89   |0.383 |0.873  |0.305   |0.259 |1.179  |0.240     |0.193 |1.242  |
|VisibleHuman|8.669 |9.730 |0.893  |12.177|0.714  |2.936   |2.307 |1.272  |2.651     |2.050 |1.293  |
```
### CPU: Core i7, Precision: float, Gang size: 16
```
|            |scalar|   shortvec   |    simd      |scalar 2|    simd2     |scalar 2.1|   simd 2.1   |
|            |      | time |speedup| time |speedup|        | time |speedup|          | time |speedup|
|------------|------|------|-------|------|-------|--------|------|-------|----------|------|-------|
|PlasticSkull|0.332 |0.399 |0.833  |0.394 |0.844  |0.306   |0.259 |1.179  |0.249     |0.199 |1.254  |
|VisibleHuman|8.684 |9.901 |0.877  |12.309|0.705  |2.940   |2.310 |1.273  |2.647     |2.017 |1.312  |
```
### CPU: Core i7, Precision: double, Gang size: 8
```
|            |scalar|   shortvec   |    simd      |scalar 2|    simd2     |scalar 2.1|   simd 2.1   |
|            |      | time |speedup| time |speedup|        | time |speedup|          | time |speedup|
|------------|------|------|-------|------|-------|--------|------|-------|----------|------|-------|
|PlasticSkull|0.353 |0.411 |0.860  |0.474 |0.745  |0.310   |0.303 |1.023  |0.247     |0.245 |1.011  |
|VisibleHuman|9.058 |10.180|0.890  |13.043|0.695  |2.950   |2.868 |1.028  |2.712     |2.573 |1.054  |
```
### CPU: Core i7, Precision: double, Gang size: 16
```
|            |scalar|   shortvec   |    simd      |scalar 2|    simd2     |scalar 2.1|   simd 2.1   |
|            |      | time |speedup| time |speedup|        | time |speedup|          | time |speedup|
|------------|------|------|-------|------|-------|--------|------|-------|----------|------|-------|
|PlasticSkull|0.355 |0.469 |0.758  |0.493 |0.720  |0.308   |0.303 |1.018  |0.248     |0.238 |1.040  |
|VisibleHuman|9.046 |10.403|0.870  |13.275|0.681  |2.950   |2.884 |1.023  |2.660     |2.603 |1.022  |
```
### CPU: Xeon Phi, Precision: float, Gang size: 16
```
|            |scalar |   shortvec    |     simd      |scalar 2|    simd2     |scalar 2.1|   simd 2.1   |
|            |       | time  |speedup| time  |speedup|        | time |speedup|          | time |speedup|
|------------|-------|-------|-------|-------|-------|--------|------|-------|----------|------|-------|
|PlasticSkull|4.681  |4.171  |1.122  |4.853  |0.965  |3.529   |3.504 |1.007  |3.460     |3.356 |1.031  |
|VisibleHuman|142.434|139.630|1.020  |308.793|0.461  |33.797  |33.402|1.012  |33.632    |32.436|1.037  |
```
### CPU: Xeon Phi, Precision: double, Gang size: 16
```
|            |scalar |   shortvec    |     simd      |scalar 2|    simd2     |scalar 2.1|   simd 2.1   |
|            |       | time  |speedup| time  |speedup|        | time |speedup|          | time |speedup|
|------------|-------|-------|-------|-------|-------|--------|------|-------|----------|------|-------|
|PlasticSkull|5.040  |4.824  |1.045  |5.812  |0.867  |3.604   |3.764 |0.957  |3.546     |3.622 |0.979  |
|VisibleHuman|153.055|151.935|1.007  |369.645|0.414  |34.393  |36.163|0.951  |34.413    |35.490|0.970  |
```

## Marching Tetrahedra
### CPU: Core i7, Precision: float, Gang size: 8
```
|            |scalar |      simd     |    simd 2     |
|            |       | time  |speedup| time  |speedup|
|------------|-------|-------|-------|-------|-------|
|PlasticSkull|0.774  |1.101  |0.704  |0.951  |0.815  |
|VisibleHuman|1.380  |2.168  |0.636  |1.697  |0.813  |
```
### CPU: Core i7, Precision: float, Gang size: 16
```
|            |scalar |      simd     |    simd 2     |
|            |       | time  |speedup| time  |speedup|
|------------|-------|-------|-------|-------|-------|
|PlasticSkull|0.762  |1.152  |0.662  |0.960  |0.794  |
|VisibleHuman|1.372  |2.908  |0.654  |1.721  |0.798  |
```
### CPU: Core i7, Precision: double, Gang size: 8
```
|            |scalar |      simd     |    simd 2     |
|            |       | time  |speedup| time  |speedup|
|------------|-------|-------|-------|-------|-------|
|PlasticSkull|0.749  |1.148  |0.652  |0.936  |0.800  |
|VisibleHuman|1.365  |2.207  |0.618  |1.690  |0.807  |
```
### CPU: Core i7, Precision: double, Gang size: 16
```
|            |scalar |      simd     |    simd 2     |
|            |       | time  |speedup| time  |speedup|
|------------|-------|-------|-------|-------|-------|
|PlasticSkull|0.765  |1.210  |0.632  |1.008  |0.758  |
|VisibleHuman|1.357  |2.246  |0.604  |1.800  |0.754  |
```
### CPU: Xeon Phi, Precision: float, Gang size: 16
```
|            |scalar |      simd     |    simd 2     |
|            |       | time  |speedup| time  |speedup|
|------------|-------|-------|-------|-------|-------|
|PlasticSkull|13.243 |14.434 |0.917  |6.880  |1.925  |
|VisibleHuman|22.729 |26.691 |0.852  |12.481 |1.821  |
```
### CPU: Xeon Phi, Precision: double, Gang size: 16
```
|            |scalar |      simd     |    simd 2     |
|            |       | time  |speedup| time  |speedup|
|------------|-------|-------|-------|-------|-------|
|PlasticSkull|13.682 |15.843 |0.864  |8.115  |1.686  |
|VisibleHuman|23.512 |29.229 |0.804  |14.620 |1.608  |
```
From the results it can be seen that, though these methods are trivially
parallelizable (eg. using multi-threading), vectorization does not produce
good results and often hurts the performance. This is probably due to low
compute-to-data-access ratio and the many random accesses due to the use
of look up tables.

# *Datasets
The original PlasticSkull and VisibleHuman datasets can be found here:
http://placid.nlm.nih.gov/community/21. These datasets can be opened in
ParaView and converted to the legacy VTK formats that our applications
accept. The PlasticSkull volumetric dataset mentioned above is the same as
the original except for the last slice which is corrupt in the original.
The VisibleHuman dataset uses only the last 512 slices of the original
dataset. To generate the tetrahedra mesh datasets, ParaView's
tetrahedralize filter was used on the volumetric datasets. When VisibleHuman
is tetraheralized, the generated data is too large. Therefore, only a
subset of the volumetric data was used (128-383, 128-383, 0-255).
